# <img src="assets/logo.png" width="60px" align="center"> VideoVerse: How Far is Your T2V Generator from a World Model?

Official repository for the paper ["VideoVerse: How Far is Your T2V Generator from a World Model?"](https://www.arxiv.org/abs/2506.02161).

[ğŸŒ Webpage](https://www.naptmn.cn/Homepage_of_VideoVerse/) [ğŸ“– Paper](https://www.arxiv.org/abs/2506.02161) [ğŸ¤— Huggingface Dataset](https://huggingface.co/datasets/NNaptmn/VideoVerse) [ğŸ† Leaderboard](https://www.naptmn.cn/Homepage_of_VideoVerse/#leaderboard)

## ğŸ”¥ News
- **[2025.09.29]** ğŸ”¥ TBD

## Introduction


## ğŸ”§ How to Start


VideoVerse is organized for easy benchmarking of T2V models:

### ğŸ“‘ Prompt Files


### Generate Images & Directory Organization

### ğŸ§ª Evaluation with VLM

1. **Set variables:**
   
2. **Run evaluation:**
   
3. **Summarize results:**
   

### ğŸ“Š Evaluation Results


1. **Start service:**
   ```bash
   pip install vllm
   vllm serve --model checkpoints/Qwen2.5-VL-72B-Instruct --port 8000 --host 0.0.0.0 --dtype bfloat16
   ```
2. **Update your evaluation command to use the Qwen2.5-VL endpoint.**

### ğŸ“œ Evaluation of Text Rendering

1. **Preparation:**
   
2. **Run evaluation:**
   

## ğŸ“£ Citation

```

## ğŸ™‹â€â™‚ï¸ Questions?

Open an [issue](https://github.com/Zeqing-Wang/VideoVerse/issues) or start a [discussion](https://github.com/Zeqing-Wang/VideoVerse/discussions).

**Enjoy using VideoVerse!** ğŸš€ğŸ–¼ï¸ğŸ¤–
